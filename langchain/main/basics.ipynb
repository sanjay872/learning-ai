{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b23d260c",
   "metadata": {},
   "source": [
    "Install langchain required libraries\n",
    "- langchain_openai for using the openai model\n",
    "- langchain_core for using chat object like SystemMessage and HumanMessage\n",
    "- langchain_community for\n",
    "- tavily-python for using tavily search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aee0c075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet -U langchain_openai langchain_core langchain_community tavily-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e55b461",
   "metadata": {},
   "source": [
    "Load Env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5336be73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8376237",
   "metadata": {},
   "source": [
    "Create the open ai model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c8de463",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "gpt_4 = ChatOpenAI(model=\"gpt-4o\",temperature=0)\n",
    "gpt_3 = ChatOpenAI(model=\"gpt-3.5-turbo-0125\",temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fd5547",
   "metadata": {},
   "source": [
    "Passing messages into the openai model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18bc2c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 12, 'total_tokens': 21, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CIcPJE1zhhGtsimBOmsiuhvWoj9h6', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--db635313-a8fa-4b5d-834f-b46dff79daa7-0', usage_metadata={'input_tokens': 12, 'output_tokens': 9, 'total_tokens': 21, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# creating a message\n",
    "msg = HumanMessage(content=\"Hello world\",name=\"sanjay\")\n",
    "\n",
    "# convert message into a list\n",
    "message = [msg]\n",
    "\n",
    "# sent the message into the model\n",
    "gpt_4.invoke(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b8c050",
   "metadata": {},
   "source": [
    "Using Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77b70ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanja\\AppData\\Local\\Temp\\ipykernel_25952\\4082643872.py:3: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  tavily_search=TavilySearchResults(max_results=3)\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tavily_search=TavilySearchResults(max_results=3)\n",
    "search_results=tavily_search.invoke(\"What is langgraph?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f5d2a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'What is LangGraph? - GeeksforGeeks',\n",
       "  'url': 'https://www.geeksforgeeks.org/machine-learning/what-is-langgraph/',\n",
       "  'content': '# What is LangGraph?\\n\\nLast Updated : \\n25 Aug, 2025\\n\\nSuggest changes\\n\\n1 Like\\n\\nLangGraph is an open-source framework built by LangChain that streamlines the creation and management of AI agent workflows. At its core, LangGraph combines large language models (LLMs) with graph-based architectures allowing developers to map, organize and optimize how AI agents interact and make decisions.',\n",
       "  'score': 0.93497354},\n",
       " {'title': 'LangGraph Tutorial: What Is LangGraph and How to Use It?',\n",
       "  'url': 'https://www.datacamp.com/tutorial/langgraph-tutorial',\n",
       "  'content': \"# LangGraph Tutorial: What Is LangGraph and How to Use It?\\n\\nLangGraph is a library within the LangChain ecosystem that provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured and efficient manner.\\n\\nJun 26, 2024  Â· 12 min read [...] Imagine you're building a complex, multi-agent large language model (LLM) application. It's exciting, but it comes with challenges: managing the state of various agents, coordinating their interactions, and handling errors effectively. This is where LangGraph can help.\\n\\nLangGraph is a library within the LangChain ecosystem designed to tackle these challenges head-on. LangGraph provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured manner. [...] For applications requiring autonomous decision-making, LangGraph enables the creation of agents that can perform tasks independently based on user inputs and predefined logic.\\n\\nThese agents can execute complex workflows, interact with other systems, and adapt to new information dynamically. LangGraph's structured framework ensures that each agent operates efficiently and effectively, making it suitable for tasks like automated customer support, data processing, and system monitoring.\",\n",
       "  'score': 0.9332426},\n",
       " {'title': 'LangGraph: A Framework for Building Stateful Multi-Agent LLM ...',\n",
       "  'url': 'https://medium.com/@ken_lin/langgraph-a-framework-for-building-stateful-multi-agent-llm-applications-a51d5eb68d03',\n",
       "  'content': '> LangGraph is a powerful Python library designed for constructing stateful, multi-actor applications with Large Language Models (LLMs). It extends the capabilities of LangChain Expression Language (LCEL) while specifically addressing limitations in existing frameworks for agent development. As a specialized tool for creating complex LLM applications, LangGraph provides a structured approach to building sophisticated workflows that require cyclical processing patterns.',\n",
       "  'score': 0.93295}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d1d192",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practice-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
